{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a705f134-8360-4c9d-9feb-ac16d662086d",
   "metadata": {},
   "source": [
    "# üßê Find label errors with cleanlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fd61b-ed74-499d-84b6-43c9d52631b0",
   "metadata": {},
   "source": [
    "In this tutorial, we will show you how you can find possible labeling errors in your data set with the help of [*cleanlab*](https://github.com/cgnorthcutt/cleanlab) and *Rubrix*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8c719-d8f2-417a-b489-28766b2f3d6e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149f04d-8b00-409e-8e38-cc2f594e15b0",
   "metadata": {},
   "source": [
    "As shown recently by [Curtis G. Northcutt et al.](https://arxiv.org/abs/2103.14749) label errors are pervasive even in the most-cited test sets used to benchmark the progress of the field of machine learning.\n",
    "In the worst-case scenario, these label errors can destabilize benchmarks and tend to favor more complex models with a higher capacity over lower capacity models.\n",
    "\n",
    "They introduce a new principled framework to ‚Äúidentify label errors, characterize label noise, and learn with noisy labels‚Äù called **confident learning**. It is open-sourced as the [cleanlab Python package](https://github.com/cgnorthcutt/cleanlab) that supports finding, quantifying, and learning with label errors in data sets.\n",
    "\n",
    "This tutorial walks you through 5 basic steps to find and correct label errors in your data set:\n",
    "\n",
    "1. üíæ Load the data set you want to check, and a model trained on it;\n",
    "2. üíª Make predictions for the test split of your data set;\n",
    "3. üßê Get label error candidates with *cleanlab*;\n",
    "4. üî¶ Uncover label errors with *Rubrix*;\n",
    "5. üñç Correct label errors and load the corrected data set;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcc27e-29d7-4648-b7a7-527847306fd6",
   "metadata": {},
   "source": [
    "## Setup Rubrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9912b",
   "metadata": {},
   "source": [
    "If you are new to Rubrix, visit and star Rubrix for updates: ‚≠ê [Github repository](https://github.com/recognai/rubrix)\n",
    "\n",
    "If you have not installed and launched Rubrix, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "Once installed, you only need to import Rubrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee51923",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import rubrix as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f079a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install tutorial dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b55b62-0f05-4f17-94b6-e448cd4c5e0a",
   "metadata": {},
   "source": [
    "Apart from [cleanlab](https://github.com/cgnorthcutt/cleanlab), we will also install the Hugging Face libraries [transformers](https://github.com/huggingface/transformers) and [datasets](https://github.com/huggingface/datasets), as well as [PyTorch](https://pytorch.org/), that provide us with the model and the data set we are going to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac0cc7f-762c-4e53-888e-c8821a54f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cleanlab torch transformers datasets -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222d232-148b-4739-8301-11eb0e2cb832",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d612a62-92d4-4f7b-bee4-775ebb849cb6",
   "metadata": {},
   "source": [
    "Let us import all the necessary stuff in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5341ea5-b6ea-4ab8-b4e6-c76a9e65373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "from cleanlab.pruning import get_noise_indices\n",
    "\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9f8ce-b38f-4999-abbf-6ac2a3eb48b8",
   "metadata": {},
   "source": [
    "## 1. Load model and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd55dc06-45bd-4622-9284-8f656e5e7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"andi611/distilbert-base-uncased-ner-agnews\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"andi611/distilbert-base-uncased-ner-agnews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53573589-7e23-4843-bb54-129e74347964",
   "metadata": {},
   "source": [
    "We then get the test split of the MRPC data set, that we will scan for label errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bb920c-6d9c-4fbd-a6d3-2c72534e2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/dani/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"ag_news\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27f1f5f-c0cd-4ab1-bbf8-fb22368d7159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Fears for T N pension after talks Unions repre...      2\n",
       "1  The Race is On: Second Private Team Sets Launc...      3\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277bdacc-7b45-49de-9a04-d6202538e176",
   "metadata": {},
   "source": [
    "## 2. Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76780ac-2710-4189-83da-e4d1820afba3",
   "metadata": {},
   "source": [
    "Now let us use the model to get predictions for our data set, and add those to our dataset instance. We will use the `.map` functionality of the *datasets* library to process our data batch-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a9e1b-d718-4789-9ca3-79014113e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee6e2df158e4c6696a2360133f76445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model_predictions(batch):\n",
    "    # batch is a dictionary of lists\n",
    "    tokenized_input = tokenizer(\n",
    "        batch[\"text\"], padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    # get logits of the model prediction\n",
    "    logits = model(**tokenized_input).logits\n",
    "    # convert logits to probabilities\n",
    "    probabilities = torch.softmax(logits, dim=1).detach().numpy()\n",
    "    \n",
    "    return {\"probabilities\": probabilities}\n",
    "    \n",
    "# Apply predictions batch-wise\n",
    "dataset = dataset.map(\n",
    "    get_model_predictions,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b6f02-3775-4bda-b7c2-5c515d5bb619",
   "metadata": {},
   "source": [
    "## 3. Get label error candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3ff64-c177-4bb8-8233-334bc33b6846",
   "metadata": {},
   "source": [
    "To identify label error candidates the cleanlab framework simply needs the probability matrix of our predictions (`n x m`, where `n` is the number of examples and `m` the number of labels), and the potentially noisy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71b15bd-bde9-4a4f-93b0-c55b28cf6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the data as numpy arrays\n",
    "dataset.set_format(\"numpy\")\n",
    "\n",
    "# Get a boolean array of label error candidates\n",
    "label_error_candidates = get_noise_indices(\n",
    "    s=dataset[\"label\"],\n",
    "    psx=dataset[\"probabilities\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b615fa4-5d62-4a66-88a5-9a81b818707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7600\n",
      "Candidates: 163 (2.1%)\n"
     ]
    }
   ],
   "source": [
    "frac = label_error_candidates.sum()/len(dataset)\n",
    "print(\n",
    "    f\"Total: {len(dataset)}\\n\"\n",
    "    f\"Candidates: {label_error_candidates.sum()} ({100*frac:0.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f2f0e-6441-4a84-b4b5-503cc7cd7685",
   "metadata": {},
   "source": [
    "## 4. Uncover label errors in Rubrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ab494-0490-4efd-8423-25fecc4c5481",
   "metadata": {},
   "source": [
    "Now that we have a list of potential candidates, let us log them to *Rubrix* to uncover and correct the label errors.\n",
    "First we switch to a pandas DataFrame to filter out our candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc03094d-58ca-408c-8467-4bbd6351e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = dataset.to_pandas()[label_error_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceef098-f462-4587-b15c-cdebd582decd",
   "metadata": {},
   "source": [
    "Then we will turn those candidates into [TextClassificationRecords](../reference/python/python_client.rst#rubrix.client.models.TextClassificationRecord) that we will log to *Rubrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f7d5436-a829-4a74-983e-b2c827b2ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_record(row):\n",
    "    prediction = list(zip(dataset.features['label'].names, row.probabilities))\n",
    "    annotation = dataset.features['label'].names[row.label]\n",
    "        \n",
    "    return rb.TextClassificationRecord(\n",
    "        inputs=row[\"text\"],\n",
    "        prediction=prediction, \n",
    "        annotation=annotation, \n",
    "        annotation_agent=\"original_benchmark\",\n",
    "        status=\"Default\"\n",
    "    )\n",
    "        \n",
    "records = candidates.apply(make_record, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208cc5a8-f349-435c-a6c1-297e30a8e52b",
   "metadata": {},
   "source": [
    "Having our records at hand we can now log them to *Rubrix* and save them in a dataset that we call `\"agnews_label_errors\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12750a89-33ce-4655-bb15-458b33cbd872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9563aac14a84c3d922942fda1b9f410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 records logged to http://localhost:6900/agnews_label_errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='agnews_label_errors', processed=163, failed=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.log(records, name=\"agnews_label_errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043088e-3e2a-4b99-9951-c744201843ed",
   "metadata": {},
   "source": [
    "Scanning through the records in the [*Explore Mode*](../reference/rubrix_webapp_reference.rst#explore-mode) of *Rubrix*, we were able to find at least **30 clear cases** of label errors. \n",
    "A couple of examples are shown below, in which the noisy labels are shown in the upper right corner of each example.\n",
    "The predictions of the model together with their probabilities are shown below each sentence pair."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
